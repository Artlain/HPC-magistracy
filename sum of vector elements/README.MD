Лабораторная работа 1. Сумма элементов вектора.
Что распараллелено?
За основу сложения элементов векторов, взят алгоритм редукции. Его суть заключается в том, что на каждой итерации каждый поток вычисляет сумму двух элементов в массиве и сохраняет значение в одном из двух элементов. И так он складывает до того омента, пока вся сумма не окажется в нулевом элементе. На рисунке показан ход алгоритма.
![image](https://user-images.githubusercontent.com/49097229/204143778-08b5a83c-6640-45ae-88b0-b260826314a0.png)
Т.е. по сути, на каждой итерации i-ый поток считает сумму i-го элемента и середина + i элемента. 
Следует отметить, что реализованный алгоритм работает для векторов, у которых количество элементов равно 2 в степени n. Поэтмоу при инициализации массива произвольным количеством элементов, я добавляю некоторые количество нулевых элементов, чтобы сделать количество элементов в векторе равным 2 в степени n.
Описание работы функции ядра sum_reduction:
1. Каждый поток вычисляет свой индекс
2. Первая оптимизация. Вместо простой передачи каждому потоку его стартовой частичной суммы, сразу же происходит сложение и затем уже передача частичной суммы, которая хранит уже сумму двух элементов, в каждый поток. Таким образом, первая итерация алгоритма произойдёт уже при передаче значений, а значит нам нужно будет в два раза меньше нитей. Это отражено в 86 строчке при расчёте GRID_SIZE. Я делю количество элементов в массиве на количество нитей в блоке и ещё пополам.
3. Затем начинается основной цикл, который начинается с s равной середине вектора, так как первую итерацию мы уже сделали при передаче нитям значений их частичных сумм. Индекс принимает различные значения 2 в степени n, начиная с середины вектора и идя вниз. Т.е. допустим на первой итерации индекс равен 2^5, на следующей итерации индекс будет равен 2^4. И цикл будет идти так до того момента, пока не останется значимых частичных сумм внутри блока 32, что равно по сути количеству нитей в одном варпе. Под значимой частичной суммой я имею ввиду элементы массива, в которые сохраняется результат суммы двух элементов вектора. Не трудно догадаться, что если элементов допустим 16, то после первой итерации значимыми частичными суммами будут являться первые 8 элементов. После второй итерации - первые 4 элемента и тд. Внутри цикла как раз реализована операция сложения представленная на рисунке выше. Стоит отметить что в цикле работают вообще все потоки и нет простаюващих холостых потоков.
Таким образом получается заставить работать все потоки. А так как все потоки одновременно выполняются внутри одного варпа, а варпы внутри блока выполняются последовательно (одновременно только внутри варп шедулера), то такое оптимальное распределение работы на всех потоках делает алгоритм более быстрым.
Следующая оптимизация, это подсчёт частичных сумм внутри одного варпа. Это происходит после того, как значимых частичных сумм остаётся в каждом блоке всего 32 и тогда вызывается функция warpReduce, в которой в тупую прописаны суммы внутри одного варпа. И получается, что 32 потока быстро суммируют оставшиеся в каждом блоке 32 частичные суммы без холостых запусков других потоков.
4. Ещё одна важная вещь, которую нужно отметить, это то, что такой алгоритм не вызывает конфликт банков. Банк конфликт это момент, когда два потока внутри одного варпа запрашивают данные из разных кэшлиний по одному и тому же индексу. Это пофикшено тем, что как раз поток складывает элементы i и середина +i. Т.е. один поток запрашивает элементы из разных кэшлиний по одному и тому же индеексу, а вот разные потоки всегда имеют разные индексы запрашиваемых элементов внутри кэш линии.
5. Функция ядра вызывается дважды. Первый раз считаются частичные суммы в каждом из блоков. Второй раз считается результирующая сумма внутри одного блока.
Эксперименты:
![image](https://user-images.githubusercontent.com/49097229/204149226-aff49100-a2cd-4df4-b0f6-99348a0d06d0.png)
![image](https://user-images.githubusercontent.com/49097229/204149239-ddfe42e9-b5f9-492b-b4ee-18695fae5490.png)
По таблице и графику ускорения видно, что когда элементов мало, то параллельный алгоритм не даёт выигрыша или даже работает медленнее чем последовательный. Но с момента, когда количество элементов стало равно 100 000 и выше, параллельный алгоритм в разы быстрее выполняется, чем последовательный, что говорит о том, что при таком количестве данных алгоритм действительно необходимо распаралеливать, чтобы добиться быстрой работы.
